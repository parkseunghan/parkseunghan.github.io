---
title: "기계학습 최종"
categories:
  - Report
tags:
  - Report
last_modified_at: 2024-12-11T00:00:00-05:01
published: true
---

# 사이버 공격 유형 예측을 위한 머신러닝 모델 개발
## 최종보고서

기계학습 11분반 - 2팀

---

## 목차
1. [프로젝트 목적](#프로젝트-목적) 
2. [데이터 설명](#데이터-설명) 
   - 2-1. [데이터 소스](#데이터-소스) 
   - 2-2. [데이터 규모](#데이터-규모) 
   - 2-3. [특성 설명](#특성-설명) 
     - 1) [특성 구성](#특성-구성) 
     - 2) [종속 변수](#종속-변수) 
     - 3) [독립 변수](#독립-변수) 
3. [데이터 전처리](#데이터-전처리) 
   - 3-1. [결측치](#결측치) 
   - 3-2. [시계열 데이터](#시계열-데이터) 
   - 3-3. [범주형 데이터](#범주형-데이터) 
   - 3-4. [IP 주소](#IP-주소) 
   - 3-5. [포트 번호](#포트-번호) 
   - 3-6. [제외 특성](#제외-특성) 
4. [기계학습 모델](#기계학습-모델) 
   - 4-1. [모델 선택](#모델-선택) 
     - 1) [KNN (K-최근접 이웃)](#KNN-K-최근접-이웃) 
     - 2) [랜덤 포레스트](#랜덤-포레스트) 
     - 3) [SVM (서포트 벡터 머신)](#SVM-서포트-벡터-머신) 
     - 4) [심층신경망](#심층신경망) 
   - 4-2. [구조 설명](#구조-설명) 
     - 1) [랜덤 포레스트](#랜덤-포레스트) 
     - 2) [SVM (서포트 벡터 머신)](#SVM-서포트-벡터-머신) 
     - 3) [심층신경망](#심층신경망) 
5. [실험 결과](#실험-결과) 
   - 5-1. [학습 과정](#학습-과정) 
     - 1) [KNN](#KNN) 
     - 2) [랜덤 포레스트](#랜덤-포레스트) 
     - 3) [SVM](#SVM) 
     - 4) [심층 신경망](#심층-신경망) 
   - 5-2. [성능 평가 결과](#성능-평가-결과) 
     - 1) [정확도](#정확도) 
     - 2) [정밀도, 재현율, F1-Score](#정밀도-재현율-F1-Score) 
   - 5-3. [결론](#결론) 

---

## 1. 프로젝트 목적
사이버 보안 공격 데이터를 분석하여 다양한 공격 유형을 예측하고 분류하기 위한 기계학습 모델을 개발하는 것을 목표로 함. 이를 통해 다음과 같은 목표를 달성하고자 함.

- 실시간 대응 체계 구축: 모델을 통해 사전에 공격 유형을 예측하고, 적절한 대응 조치를 취할 수 있는 체계를 마련하여 보안 사고의 발생을 예방하거나 피해를 최소화할 수 있음.
- 공격 탐지: 공격 유형을 미리 예측하고 분류하여 수동적 보안 관리에서 능동적 방어로 전환할 수 있음.

---

## 2. 데이터 설명

### 2-1. 데이터 소스
사용된 데이터셋: Cyber Security Attacks (파일명: `cybersecurity_attacks.csv`)  
데이터 출처: Incribo. (2024). Cyber Security Attacks. Retrieved December 8, 2024.
<https://github.com/incribo-inc/cybersecurity_attacks> (github),
<https://www.kaggle.com/datasets/teamincribo/cyber-security-attacks/data> (Kaggle)

### 2-2. 데이터 규모
- 40,000개 열
- 25개 특성
- 목표 변수: Attack Type (Malware, DDoS, Intrusion)

### 2-3. 특성 설명

#### 1) 특성 구성
- 공격 트래픽으로만 구성되어 있어 정상 트래픽의 데이터는 포함되지 않음.
- 25개의 특성은 범주형(13개), 수치형(4개), 시간(1개), IP 주소(3개), 위치(1개), 텍스트(3개)로 구성됨.

#### 2) 종속 변수
- Attack Type (Malware, DDoS, Intrusion)

#### 3) 독립 변수
- Protocol: 통신 프로토콜 (TCP, UDP, ICMP)
- Packet Type: 패킷 유형 (Data, Control)
- Traffic Type: 트래픽 유형 (HTTP, DNS, FTP)
- Attack Signature: 공격 시그니처 패턴
- Action Taken: 취해진 조치 (Blocked, Logged, Ignored)
- Severity Level: 심각도 수준 (Low, Medium, High)
- User Information: 사용자 이름
- Network Segment: 네트워크 세그먼트 (Segment A, B, C)
- Log Source: 로그 출처 (Server, Firewall)
- Malware Indicators: IoC (Indicators of Compromise) 탐지 여부
- Alerts/Warnings: 경고 발생 여부
- IDS/IPS Alerts: IDS/IPS 경고 존재 여부
- Source Port: 출발지 포트 번호
- Destination Port: 목적지 포트 번호
- Packet Length: 패킷 크기
- Anomaly Scores: 이상 점수 (0-100)
- Timestamp: 날짜/시간 형식 (YYYY-MM-DD HH:MM:SS)
- Source IP Address: 출발지 IP 주소
- Destination IP Address: 목적지 IP 주소
- Proxy Information: 프록시 서버 정보
- Geo-location Data: 지리적 위치 정보
- Payload Data: 텍스트 형태의 페이로드 데이터
- Device Information: 디바이스/브라우저 정보
- Firewall Logs: 방화벽 로그 존재 여부

---

## 3. 데이터 전처리

```python
import pandas as pd
import numpy as np

# 데이터 로드
cyber = pd.read_csv('cybersecurity_attacks.csv')

y = cyber['Attack Type'] # 타겟 변수 분리
```

### 3-1. 결측치
값이 있거나, 없거나 한 데이터에 대해서는 0과 1로 변환(nan -> 0). 프록시 같은 경우도 개별 IP보다는 사용 여부가 중요하므로 0과 1로 처리

- Malware Indicators: 20,000건 (IoC Detected, nan)
- Alerts/Warnings: 20,067건 (Alert Triggered, nan)
- Firewall Logs: 19,961건 (Log Data, nan)
- IDS/IPS Alerts: 20,050건 (Alert Data, nan)
- Proxy Information: 19,851건 (0.0.0.0, nan)

    ```python
    binary_features = [
        'Malware Indicators',
        'Alerts/Warnings',
        'Firewall Logs',
        'IDS/IPS Alerts',
        'Proxy Information'
    ]

    for feature in binary_features:
        cyber[feature] = cyber[feature].notna().astype(int)
    ```

### 3-2. 시계열 데이터
UTC 시간대로 시계열 데이터를 표준화 후 시간 관련 특성 생성

- Timestamp: YYYY-MM-DD HH:MM:SS

    ```python
    cyber['Timestamp'] = pd.to_datetime(cyber['Timestamp'])

    # 시간 관련 특성 추출
    cyber['hour'] = cyber['Timestamp'].dt.hour
    cyber['day_of_week'] = cyber['Timestamp'].dt.dayofweek
    cyber['month'] = cyber['Timestamp'].dt.month
    cyber['is_weekend'] = cyber['Timestamp'].dt.dayofweek.isin([5,6]).astype(int)

    time_features = ['hour', 'day_of_week', 'month', 'is_weekend']

    # 원본 timestamp 컬럼 삭제
    cyber = cyber.drop('Timestamp', axis=1)
    ```

### 3-3. 범주형 데이터
원-핫 인코딩으로 범주형 데이터를 정량적으로 변환

- Protocol: ICMP, UDP, TCP
- Packet Type: Data, Control
- Traffic Type: HTTP, DNS, FTP
- Attack Type: Malware, DDoS, Intrusion
- Attack Signature: Known Pattern A, Known Pattern B
- Action Taken: Logged, Blocked, Ignored
- Severity Level: Low, Medium, High
- Network Segment: Segment A, Segment B, Segment C
- Log Source: Server, Firewall

```python
import pandas as pd
from sklearn.preprocessing import OneHotEncoder

# 범주형 데이터 목록
categorical_features = [
    "Source Port",
    "Destination Port",
    "Protocol",
    "Packet Type",
    "Traffic Type",
    "Attack Signature",
    "Action Taken",
    "Severity Level",
    "Network Segment",
    "Log Source",
    "Source_Subnet",
    "Destination_Subnet",
]

# OneHotEncoder 설정
onehot_encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')

# 범주형 데이터를 원-핫 인코딩
encoded_data = onehot_encoder.fit_transform(cyber[categorical_features])

# 인코딩된 데이터의 피처 이름을 수동으로 생성
encoded_feature_names = []
for feature_name, categories in zip(categorical_features, onehot_encoder.categories_):
    for category in categories[1:]:  # Skip the first category due to drop='first'
        encoded_feature_names.append(f"{feature_name}_{category}")

# 인코딩된 데이터를 데이터프레임으로 변환
encoded_df = pd.DataFrame(encoded_data, columns=encoded_feature_names)

# 원래 데이터프레임에서 범주형 열을 제거하고 인코딩된 데이터와 합치기
cyber_encoded = pd.concat([cyber.drop(columns=categorical_features).reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)
```

### 3-4. IP 주소
IP 주소를 서브넷 클래스로 분류 후 원-핫 인코딩

- Source IP Address: X.X.X.X
- Destination IP Address: X.X.X.X

    ```python
    def get_subnet_class(ip):
        try:
            first_octet = int(ip.split('.')[0])
            if 1 <= first_octet <= 126:
                return 'A'
            elif 128 <= first_octet <= 191:
                return 'B'
            elif 192 <= first_octet <= 223:
                return 'C'
            else:
                return 'D_E'  # D와 E클래스는 통합
        except:
            return 'Invalid'

    # 서브넷 클래스 추출
    cyber['Source_Subnet'] = cyber['Source IP Address'].apply(get_subnet_class)
    cyber['Destination_Subnet'] = cyber['Destination IP Address'].apply(get_subnet_class)

    # 원본 IP 컬럼 제거
    cyber = cyber.drop(['Source IP Address', 'Destination IP Address'], axis=1)
    ```

### 3-5. 포트 번호
포트 번호를 범주화

- Source Port: 1027~65530
- Destination Port: 1024~65535

    ```python
    port_features = ['Source Port', 'Destination Port']

    def categorize_port(port):
        if port < 1024:
            return 'well-known'  # well-known
        elif port < 49152:
            return 'registered'  # registered
        else:
            return 'dynamic'  # dynamic

    for feature in port_features:
        # 기존 열에 범주화된 값 덮어쓰기
        cyber[feature] = cyber[feature].apply(categorize_port)
    ```

### 3-6. 제외 특성
각 레코드가 unique로 고유성이 매우 높고, 공격 유형 분류에 직접적인 영향을 미치지 않음.

- **Payload Data**: 사용자 이름 정보로 특정 사용자의 공격 패턴을 알고자 하는 것이 아니므로 제외.
- **User Information**: 브라우저/OS 정보가 포함된 User-Agent 문자열로, 실제 공격 특성을 반영하지 않음.
- **Device Information**: 도시/주 정보만 포함되어 있어 정확한 위치 파악이 어렵고 IP 주소로부터 더 정확한 위치 정보를 얻을 수 있음.
- **Geo-location Data**: 

    ```python
    features_to_remove = [
        'Attack Type', # 변수 분리를 위해 추가
        'Payload Data',
        'User Information',
        'Device Information',
        'Geo-location Data'
    ]

    cyber = cyber.drop(features_to_remove, axis=1)
    ```

---

## 4. 기계학습 모델

### 4-1. 모델 선택
1) **KNN (K-최근접 이웃)**
   - 타겟 변수를 참고하여 공격 유형을 분류하는 모델. 대규모 데이터셋에서는 계산 비용이 크기 때문에 다른 모델을 주로 사용.

2) **랜덤 포레스트**
   - 여러 개의 결정 트리를 생성하여 예측을 수행하고, 각 트리의 예측을 평균하여 최종 예측을 도출함. 이는 과적합을 방지하고 일반화 능력을 높이는 데 유리.

3) **SVM (서포트 벡터 머신)**
   - 데이터 포인트를 분리하는 최적의 경계를 찾는 방법으로, 비선형 문제에 강한 성능을 보임.

4) **심층신경망**
   - 여러 개의 은닉층을 가진 인공 신경망으로 복잡한 패턴을 학습할 수 있는 능력이 뛰어나며, 대량의 데이터에 적합.

### 4-2. 구조 설명
1) **랜덤 포레스트**
   - 다수의 결정 트리로 구성되어 있으며, 각 트리는 훈련 데이터의 랜덤 샘플을 기반으로 생성됨. 각 트리는 독립적으로 예측을 수행하고, 최종 예측은 모든 트리의 예측 결과의 평균으로 결정됨. 이는 과적합을 줄이고 안정성을 높임.

2) **SVM (서포트 벡터 머신)**
   - 차원 공간에서 데이터 포인트를 분리하는 최적의 경계를 찾음. 커널 함수를 사용하여 비선형 데이터도 처리할 수 있으며, 매개변수 C와 gamma를 통해 결정 경계의 복잡성을 조정할 수 있음.

3) **심층신경망**
   - 입력층, 여러 개의 은닉층 및 출력층으로 구성됨. 각 은닉층은 여러 뉴런으로 이루어져 있으며, 활성화 함수로 ReLU를 사용하여 비선형성을 추가. 마지막 출력층에서는 softmax 함수를 사용하여 다중 클래스 분류 문제를 해결.

---

## 5. 실험 결과

### 5-1. 학습 과정
- 전처리 결과 특성은 총 30개로 확장됨.
```
 0   Packet Length                     40000 non-null  int64  
 1   Malware Indicators                40000 non-null  int64  
 2   Anomaly Scores                    40000 non-null  float64
 3   Alerts/Warnings                   40000 non-null  int64  
 4   Proxy Information                 40000 non-null  int64  
 5   Firewall Logs                     40000 non-null  int64  
 6   IDS/IPS Alerts                    40000 non-null  int64  
 7   hour                              40000 non-null  int32  
 8   day_of_week                       40000 non-null  int32  
 9   month                             40000 non-null  int32  
 10  is_weekend                        40000 non-null  int64  
 11  Source Port_registered            40000 non-null  float64
 12  Destination Port_registered       40000 non-null  float64
 13  Protocol_TCP                      40000 non-null  float64
 14  Protocol_UDP                      40000 non-null  float64
 15  Packet Type_Data                  40000 non-null  float64
 16  Traffic Type_FTP                  40000 non-null  float64
 17  Traffic Type_HTTP                 40000 non-null  float64
 18  Attack Signature_Known Pattern B  40000 non-null  float64
 19  Action Taken_Ignored              40000 non-null  float64
 20  Action Taken_Logged               40000 non-null  float64
 21  Severity Level_Low                40000 non-null  float64
 22  Severity Level_Medium             40000 non-null  float64
 23  Network Segment_Segment B         40000 non-null  float64
 24  Network Segment_Segment C         40000 non-null  float64
 25  Log Source_Server                 40000 non-null  float64
 26  Source_Subnet_B                   40000 non-null  float64
 27  Source_Subnet_C                   40000 non-null  float64
 28  Destination_Subnet_B              40000 non-null  float64
 29  Destination_Subnet_C              40000 non-null  float64
```
- 각 모델은 훈련 데이터셋을 사용하여 학습을 진행하며, 이를 통해 최적의 하이퍼파라미터를 찾기 위해 GridSearchCV를 사용.

#### 모델별 하이퍼파라미터 설정
- **랜덤 포레스트**: n_estimators, max_depth, min_samples_split, min_samples_leaf
- **SVM**: C, gamma, kernel (linear, rbf)
- **DNN**: units, dropout_rate, learning_rate, batch_size, epochs

| 모델          | 정확도 | 정밀도 | 재현율 | F1 점수 |
|-------------|-------|--------|-------|---------|
| 랜덤 포레스트 | 0.33  | 0.33   | 0.42  | 0.37    |
| SVM         | 0.34  | 0.41   | 0.37  | 0.33    |
| DNN         | 0.34  | 0.36   | 0.44  | 0.40    |

#### 1) KNN
K-NN으로 모델을 만들기에는 적합하지 않다는 결론이 나온 이유는 다음과 같다.
- 최적의 K값은 1로 결정되었고 교차 검증 정확도는 0.3325로 나오고 이것은 최적화된 모델이 훈련 데이터를 기반으로 얻은 평균 모든 공격 유형에 대해 성능이 비슷하게 나타났음.

```python
#하이퍼파라미터 튜닝
param_grid = {'n_neighbors': range(1, 21)}
knn = KNeighborsClassifier()
grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', verbose=1)
grid_search.fit(X_train, y_train)

# 교차 검증
best_k = grid_search.best_params_['n_neighbors']
print(f"최적의 k 값: {best_k}")
print(f"교차 검증 정확도: {grid_search.best_score_}")

#  데이터 평가
best_knn = grid_search.best_estimator_
y_pred = best_knn.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
classification_results = classification_report(y_test, y_pred, target_names=target_columns, zero_division=0)

print(f"\n테스트 정확도: {accuracy:.4f}")
print(classification_results)
```

![KNN - 1](/assets/images/그림2.png)

#### 결과 분석
- **정밀도**: DDoS 공격의 정밀도는 0.32, Intrusion 공격의 정밀도는 0.33, Malware 공격의 정밀도는 0.34. 정밀도의 값들이 낮은 값으로 나타나는 것을 보아 예측이 정확하지 않다는 것을 알 수 있음.
- **재현율**: DDoS 공격의 재현율은 0.34, 침입(Intrusion) 공격의 재현율은 0.32, 악성코드(Malware) 공격의 재현율은 0.33임. 재현율이 낮다는 것은 모델이 실제로 존재하는 공격을 놓치는 경우가 많다는 것을 알 수 있음.
- **F1 점수**: F1 점수는 정밀도와 재현율의 조화 평균으로, 두 지표의 균형을 나타냄. DDoS 공격의 F1 점수는 0.33, 침입(Intrusion) 공격의 F1 점수는 0.33, 악성코드(Malware) 공격의 F1 점수는 0.34임. F1 점수가 낮고 비슷한 수준이라는 것은 모델이 정밀도와 재현율 모두에서 좋지 않은 성능을 가진 모델이라는 것을 알 수 있음.

#### 2) 랜덤 포레스트
특성 중요도 추출 결과 상위 5개 특성을 기반으로 훈련됨.

![특성중요도 - 1](/assets/images/그림1.png)

- Packet Length, Anomaly Scores, hour, month, day_of_week

```python
'''
하이퍼파라미터 튜닝
'''
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20, 30],
}
```

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# 튜닝 전
# rf_model = RandomForestClassifier(max_depth=10, n_estimators=100, random_state=42)

# 튜닝 후
rf_model = RandomForestClassifier(max_depth=10, n_estimators=100, min_samples_split=2, min_samples_leaf=2, random_state=42)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)
print(classification_report(y_test, y_pred))
```

|   | 튜닝 전 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.34 | 0.32 |  |
| 재현율 | 0.37 | 0.31 | 0.31 |  |
| F1 점수 | 0.35 | 0.32 | 0.32 | |
| 정확도 |  | | 0.33 | |

|   | 튜닝 후 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.33 | 0.34 |  |
| 재현율 | 0.42 | 0.26 | 0.33 |  |
| F1 점수 | 0.37 | 0.29 | 0.33 |  |
| 정확도 | | | 0.33 | |

- **결론**: 하이퍼파라미터 튜닝을 통해 일부 성능 지표가 개선되었지만, 전체적인 모델 성능은 여전히 낮은 편임.


#### 3) SVM
최적의 파라미터 값을 찾은 후 튜닝 전후를 비교함.

- 'C': 10, 'gamma': 'scale', 'kernel': 'linear'

```python
import pandas as pd
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler

# 데이터 준비
X = cyber_encoded[['Packet Length', 'Anomaly Scores', 'hour', 'month', 'day_of_week']]  # 상위 5개 특성

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 데이터 스케일링
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# SVM 모델 훈련

# 튜닝 전
# model_svm = svm.SVC(random_state=42)

# 튜닝 후
model = svm.SVC(C=10, gamma='scale', kernel='rbf', random_state=42)

model_svm.fit(X_train_scaled, y_train)

# 모델 평가
y_pred_svm = model_svm.predict(X_test_scaled)
print(classification_report(y_test, y_pred_svm))
```

|   | 튜닝 전 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.33 | 0.34 |  |
| 재현율 | 0.41 | 0.23 | 0.36 |  |
| F1 점수 | 0.37 | 0.27 | 0.35 |  |
| 정확도 | | | 0.33 | |


|   | 튜닝 후 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.33 | 0.33 |  |
| 재현율 | 0.35 | 0.30 | 0.34 |  |
| F1 점수 | 0.34 | 0.31 | 0.33 |  |
| 정확도 | | | 0.33 | |

- **결론**: 튜닝 후 전체적인 성능이 감소. 기본값으로 진행했을 때 더 나은 성능을 보이지만, 그럼에도 여전히 낮은 성능을 보임.

#### 4) 심층 신경망

**튜닝 전**
- 클래스 0에서 상대적으로 높은 재현율을 보임.

|   | 튜닝 전 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.34 | 0.35 | 0.33 |  |
| 재현율 | 0.44 | 0.32 | 0.25 |  |
| F1 점수 | 0.38 | 0.34 | 0.28 |  |
| 정확도 | | | 0.34 | |

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import classification_report

# 데이터 준비
X = cyber_encoded[['Packet Length', 'Anomaly Scores', 'hour', 'month', 'day_of_week']]  # 상위 5개 특성

# 타겟 변수 레이블 인코딩
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# 원-핫 인코딩
y_one_hot = to_categorical(y_encoded)

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)

# 데이터 스케일링
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# DNN 모델 구축
model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))  # 첫 번째 은닉층
model.add(Dense(64, activation='relu'))  # 두 번째 은닉층
model.add(Dense(64, activation='relu'))  # 세 번째 은닉층
model.add(Dense(y_one_hot.shape[1], activation='softmax'))  # 출력층 (다중 클래스)

# 모델 컴파일
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# 모델 훈련
model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)

# 모델 평가
y_pred_prob = model.predict(X_test_scaled)
y_pred = np.argmax(y_pred_prob, axis=1)  # 확률을 클래스 인덱스로 변환

# 원래 클래스 인덱스로 변환
y_true = np.argmax(y_test, axis=1)

# 모델 평가
print(classification_report(y_true, y_pred))
```

**튜닝 후**
- 클래스 0의 재현율은 0.34로 감소, 클래스 1은 0.29, 클래스 2는 0.36으로 전반적으로 낮은 재현율을 보임.

```python
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 준비
X = cyber_encoded[['Packet Length', 'Anomaly Scores', 'hour', 'month', 'day_of_week']]  # 상위 5개 특성


# 타겟 변수 레이블 인코딩
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# 데이터 스케일링
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

def create_dnn_model(input_dim, num_classes):
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(256, activation='relu', input_dim=input_dim),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.3),

        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.2),

        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.1),

        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

def train_dnn(X_train, X_test, y_train, y_test):
    print("\n## Deep Neural Network 학습 시작")

    # 모델 생성
    num_classes = len(np.unique(y_train))
    model = create_dnn_model(X_train.shape[1], num_classes)

    # 학습률 조정 함수
    def scheduler(epoch, lr):
        if epoch > 20:  # 20 에포크 이후
            lr = lr * tf.math.exp(-0.1)  # 학습률을 10% 감소
        return float(lr)  # 항상 float 타입 반환

    # 콜백 정의
    early_stopping = EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    )

    lr_scheduler = LearningRateScheduler(scheduler)  # lr_scheduler 정의 추가

    callbacks = [
        tf.keras.callbacks.ModelCheckpoint(
            filepath="convnet_from_scratch.keras",
            save_best_only=True,
            monitor="val_loss"
        ),
        lr_scheduler
    ]

    # 모델 학습
    history = model.fit(
        X_train, y_train,
        validation_split=0.2,
        epochs=200,
        batch_size=64,
        callbacks=callbacks,
        verbose=1
    )

    # 학습 과정 시각화
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.savefig('dnn_training_history.png')
    plt.close()

    # 예측 및 성능 평가
    y_pred = np.argmax(model.predict(X_test), axis=1)

    # 성능 지표 출력
    print("\n## 성능 평가 결과")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # 혼동 행렬 시각화
    plt.figure(figsize=(8, 6))
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.savefig('dnn_confusion_matrix.png')
    plt.close()

    # 예측 확률 분포 시각화
    y_prob = model.predict(X_test)
    plt.figure(figsize=(10, 6))
    for i in range(num_classes):
        plt.hist(y_prob[:, i], bins=50, alpha=0.5, label=f'Class {i}')
    plt.title('Prediction Probability Distribution')
    plt.xlabel('Probability')
    plt.ylabel('Count')
    plt.legend()
    plt.tight_layout()
    plt.savefig('dnn_prediction_distribution.png')
    plt.close()

    return model, y_pred

# DNN 모델 학습 및 평가
dnn_model, dnn_predictions = train_dnn(X_train_scaled, X_test_scaled, y_train, y_test)
```

|   | 튜닝 후 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.34 | 0.33 |  |
| 재현율 | 0.34 | 0.29 | 0.31 |  |
| F1 점수 | 0.32 | 0.36 | 0.34 |  |
| 정확도 | | | 0.33 | |

- **정확성**: 모델 1(튜닝 전)과 모델 2(튜닝 후)의 precision 값은 비슷한 수준임. 모델 1이 클래스 1에서 약간 더 높은 precision(0.35)을 보이고, 나머지 클래스에서는 비슷한 수준.
- **재현율**: 모델 1의 recall은 클래스 0에서 0.44로 가장 높고, 클래스 1은 0.32, 클래스 2는 0.25입니다. 반면, 모델 2는 클래스 0에서 0.34, 클래스 1에서 0.29, 클래스 2에서 0.36으로 전반적으로 낮은 recall을 보임. 모델 1이 클래스 0에 대해 더 잘 예측하고 있음을 나타냄.
- **F1-Score**: 모델 1의 f1-score는 클래스 0에서 0.38로 가장 높고, 나머지 클래스에서는 모델 1이 더 나은 성능(클래스 1: 0.34, 클래스 2: 0.28)을 보임. 모델 2의 f1-score는 전반적으로 낮음.
- **Accuracy**: 두 모델 모두 비슷한 accuracy를 보임. 모델 1의 accuracy는 0.34, 모델 2는 0.33입니다. 두 모델 모두 낮은 accuracy를 보이고 있음.

### 5-2. 성능 평가 결과
#### 1) 정확도
- 세 모델 모두 유사한 수준의 낮은 정확도를 보임. 데이터 불균형, 특성 선택, 모델의 복잡성 등의 원인이 있다고 판단됨.

#### 2) 정밀도, 재현율, F1-Score
- DNN이 클래스 0에서 가장 높은 재현율과 F1-Score를 기록했지만, 전반적으로 모든 모델이 낮은 성능을 보임.
- 랜덤 포레스트와 SVM은 특정 클래스에서는 좋은 성능을 보임. 모델에 따라 특정 클래스에 대한 예측 성능이 달라짐.

### 5-3. 결론
- 현재 데이터셋과 특성 조합으로는 네 모델 모두 유의미한 성능을 발휘하지 못함.
- 적절치 못한 특성 선택, 하이퍼파라미터 부족 등의 문제가 복합적으로 작용했다고 판단됨.
- 향후 데이터 전처리, 특성 엔지니어링, 하이퍼파라미터 튜닝, 앙상블 기법, 모델의 다양화 등을 시도하여 성능을 개선할 수 있음.

---
