---
title: "기계학습 최종"
categories:
  - Report
tags:
  - Report
last_modified_at: 2024-12-12T00:00:00-05:01
published: true
---

# 사이버 공격 유형 예측을 위한 머신러닝 모델 개발
## 최종보고서

기계학습 11분반 - 2팀

---

## 목차
1. [프로젝트 목적](#프로젝트-목적) 
2. [데이터 설명](#데이터-설명) 
   - 2-1. [데이터 소스](#데이터-소스) 
   - 2-2. [데이터 규모](#데이터-규모) 
   - 2-3. [특성 설명](#특성-설명) 
     - 1) [특성 구성](#특성-구성) 
     - 2) [종속 변수](#종속-변수) 
     - 3) [독립 변수](#독립-변수) 
3. [데이터 전처리](#데이터-전처리) 
   - 3-1. [결측치](#결측치) 
   - 3-2. [시계열 데이터](#시계열-데이터) 
   - 3-3. [범주형 데이터](#범주형-데이터) 
   - 3-4. [IP 주소](#IP-주소) 
   - 3-5. [포트 번호](#포트-번호) 
   - 3-6. [정규화](#정규화) 
   - 3-7. [제외 특성](#제외-특성) 
4. [기계학습 모델](#기계학습-모델) 
   - 4-1. [모델 선택](#모델-선택) 
     - 1) [KNN (K-최근접 이웃)](#KNN-K-최근접-이웃) 
     - 2) [랜덤 포레스트](#랜덤-포레스트) 
     - 3) [SVM (서포트 벡터 머신)](#SVM-서포트-벡터-머신) 
     - 4) [심층신경망](#심층신경망) 
   - 4-2. [구조 설명](#구조-설명) 
     - 1) [랜덤 포레스트](#랜덤-포레스트) 
     - 2) [SVM (서포트 벡터 머신)](#SVM-서포트-벡터-머신) 
     - 3) [심층신경망](#심층신경망) 
5. [실험 결과](#실험-결과) 
   - 5-1. [학습 과정](#학습-과정) 
     - 1) [KNN](#KNN) 
     - 2) [랜덤 포레스트](#랜덤-포레스트) 
     - 3) [SVM](#SVM) 
     - 4) [심층 신경망](#심층-신경망) 
   - 5-2. [성능 평가 결과](#성능-평가-결과) 
     - 1) [정확도](#정확도) 
     - 2) [정밀도, 재현율, F1-Score](#정밀도-재현율-F1-Score) 
   - 5-3. [결론](#결론) 

---

## 1. 프로젝트 목적
사이버 보안 공격 데이터를 분석하여 다양한 공격 유형을 예측하고 분류하기 위한 기계학습 모델을 개발하는 것을 목표로 함. 이를 통해 다음과 같은 목표를 달성하고자 함.

- 실시간 대응 체계 구축: 모델을 통해 사전에 공격 유형을 예측하고, 적절한 대응 조치를 취할 수 있는 체계를 마련하여 보안 사고의 발생을 예방하거나 피해를 최소화할 수 있음.
- 공격 탐지: 공격 유형을 미리 예측하고 분류하여 수동적 보안 관리에서 능동적 방어로 전환할 수 있음.

---

## 2. 데이터 설명

### 2-1. 데이터 소스
사용된 데이터셋: Cyber Security Attacks (파일명: `cybersecurity_attacks.csv`)  
데이터 출처: Incribo. (2024). Cyber Security Attacks. Retrieved December 8, 2024.
<https://github.com/incribo-inc/cybersecurity_attacks> (github),
<https://www.kaggle.com/datasets/teamincribo/cyber-security-attacks/data> (Kaggle)

### 2-2. 데이터 규모
- 40,000개 열
- 25개 특성
- 목표 변수: Attack Type (Malware, DDoS, Intrusion)

### 2-3. 특성 설명

#### 1) 특성 구성
- 공격 트래픽으로만 구성되어 있어 정상 트래픽의 데이터는 포함되지 않음.
- 25개의 특성은 범주형(13개), 수치형(4개), 시간(1개), IP 주소(3개), 위치(1개), 텍스트(3개)로 구성됨.

#### 2) 종속 변수
- Attack Type (Malware, DDoS, Intrusion)

#### 3) 독립 변수
- Protocol: 통신 프로토콜 (TCP, UDP, ICMP)
- Packet Type: 패킷 유형 (Data, Control)
- Traffic Type: 트래픽 유형 (HTTP, DNS, FTP)
- Attack Signature: 공격 시그니처 패턴
- Action Taken: 취해진 조치 (Blocked, Logged, Ignored)
- Severity Level: 심각도 수준 (Low, Medium, High)
- User Information: 사용자 이름
- Network Segment: 네트워크 세그먼트 (Segment A, B, C)
- Log Source: 로그 출처 (Server, Firewall)
- Malware Indicators: IoC (Indicators of Compromise) 탐지 여부
- Alerts/Warnings: 경고 발생 여부
- IDS/IPS Alerts: IDS/IPS 경고 존재 여부
- Source Port: 출발지 포트 번호
- Destination Port: 목적지 포트 번호
- Packet Length: 패킷 크기
- Anomaly Scores: 이상 점수 (0-100)
- Timestamp: 날짜/시간 형식 (YYYY-MM-DD HH:MM:SS)
- Source IP Address: 출발지 IP 주소
- Destination IP Address: 목적지 IP 주소
- Proxy Information: 프록시 서버 정보
- Geo-location Data: 지리적 위치 정보
- Payload Data: 텍스트 형태의 페이로드 데이터
- Device Information: 디바이스/브라우저 정보
- Firewall Logs: 방화벽 로그 존재 여부

---

## 3. 데이터 전처리

### 3-1. 결측치
값이 있거나, 없거나 한 데이터에 대해서는 0과 1로 변환(nan -> 0). 프록시 같은 경우도 개별 IP보다는 사용 여부가 중요하므로 0과 1로 처리

- Malware Indicators: 20,000건 (IoC Detected, nan)
- Alerts/Warnings: 20,067건 (Alert Triggered, nan)
- Firewall Logs: 19,961건 (Log Data, nan)
- IDS/IPS Alerts: 20,050건 (Alert Data, nan)
- Proxy Information: 19,851건 (0.0.0.0, nan)

### 3-2. 시계열 데이터
UTC 시간대로 시계열 데이터를 표준화 후 시간 관련 특성 생성

- Timestamp: YYYY-MM-DD HH:MM:SS

### 3-3. 범주형 데이터
원-핫 인코딩으로 범주형 데이터를 정량적으로 변환

- Protocol: ICMP, UDP, TCP
- Packet Type: Data, Control
- Traffic Type: HTTP, DNS, FTP
- Attack Type: Malware, DDoS, Intrusion
- Attack Signature: Known Pattern A, Known Pattern B
- Action Taken: Logged, Blocked, Ignored
- Severity Level: Low, Medium, High
- Network Segment: Segment A, Segment B, Segment C
- Log Source: Server, Firewall

### 3-4. IP 주소
IP 주소를 서브넷 클래스로 분류 후 원-핫 인코딩

- Source IP Address: X.X.X.X
- Destination IP Address: X.X.X.X

### 3-5. 포트 번호
포트 번호를 범주화

- Source Port: 1027~65530
- Destination Port: 1024~65535

### 3-6. 정규화
Min-Max 스케일러를 사용해 수치형 데이터를 0과 1 사이로 변환

- Packet Length: 64 ~ 1500
- Anomaly Scores: 0.0 ~ 100.0

### 3-7. 제외 특성
각 레코드가 unique로 고유성이 매우 높고, 공격 유형 분류에 직접적인 영향을 미치지 않음.

- **Payload Data**: 사용자 이름 정보로 특정 사용자의 공격 패턴을 알고자 하는 것이 아니므로 제외.
- **User Information**: 브라우저/OS 정보가 포함된 User-Agent 문자열로, 실제 공격 특성을 반영하지 않음.
- **Device Information**: 도시/주 정보만 포함되어 있어 정확한 위치 파악이 어렵고 IP 주소로부터 더 정확한 위치 정보를 얻을 수 있음.
- **Geo-location Data**: 

---

## 4. 기계학습 모델

### 4-1. 모델 선택
1) **KNN (K-최근접 이웃)**
   - 타겟 변수를 참고하여 공격 유형을 분류하는 모델. 대규모 데이터셋에서는 계산 비용이 크기 때문에 다른 모델을 주로 사용.

2) **랜덤 포레스트**
   - 여러 개의 결정 트리를 생성하여 예측을 수행하고, 각 트리의 예측을 평균하여 최종 예측을 도출함. 이는 과적합을 방지하고 일반화 능력을 높이는 데 유리.

3) **SVM (서포트 벡터 머신)**
   - 데이터 포인트를 분리하는 최적의 경계를 찾는 방법으로, 비선형 문제에 강한 성능을 보임.

4) **심층신경망**
   - 여러 개의 은닉층을 가진 인공 신경망으로 복잡한 패턴을 학습할 수 있는 능력이 뛰어나며, 대량의 데이터에 적합.

### 4-2. 구조 설명
1) **랜덤 포레스트**
   - 다수의 결정 트리로 구성되어 있으며, 각 트리는 훈련 데이터의 랜덤 샘플을 기반으로 생성됨. 각 트리는 독립적으로 예측을 수행하고, 최종 예측은 모든 트리의 예측 결과의 평균으로 결정됨. 이는 과적합을 줄이고 안정성을 높임.

2) **SVM (서포트 벡터 머신)**
   - 차원 공간에서 데이터 포인트를 분리하는 최적의 경계를 찾음. 커널 함수를 사용하여 비선형 데이터도 처리할 수 있으며, 매개변수 C와 gamma를 통해 결정 경계의 복잡성을 조정할 수 있음.

3) **심층신경망**
   - 입력층, 여러 개의 은닉층 및 출력층으로 구성됨. 각 은닉층은 여러 뉴런으로 이루어져 있으며, 활성화 함수로 ReLU를 사용하여 비선형성을 추가. 마지막 출력층에서는 softmax 함수를 사용하여 다중 클래스 분류 문제를 해결.

---

## 5. 실험 결과

### 5-1. 학습 과정
- 전처리 결과 특성은 총 30개로 확장됨.
- 각 모델은 훈련 데이터셋을 사용하여 학습을 진행하며, 이를 통해 최적의 하이퍼파라미터를 찾기 위해 GridSearchCV를 사용.

#### 모델별 하이퍼파라미터 설정
- **랜덤 포레스트**: n_estimators, max_depth, min_samples_split, min_samples_leaf
- **SVM**: C, gamma, kernel (linear, rbf)
- **DNN**: units, dropout_rate, learning_rate, batch_size, epochs

| 모델          | 정확도 | 정밀도 | 재현율 | F1 점수 |
|-------------|-------|--------|-------|---------|
| 랜덤 포레스트 | 0.33  | 0.33   | 0.42  | 0.37    |
| SVM         | 0.34  | 0.41   | 0.37  | 0.33    |
| DNN         | 0.34  | 0.36   | 0.44  | 0.40    |

#### 1) KNN
K-NN으로 모델을 만들기에는 적합하지 않다는 결론이 나온 이유는 다음과 같다.
- 최적의 K값은 1로 결정되었고 교차 검증 정확도는 0.3325로 나오고 이것은 최적화된 모델이 훈련 데이터를 기반으로 얻은 평균 모든 공격 유형에 대해 성능이 비슷하게 나타났음.

#### 결과 분석
- **정밀도**: DDoS 공격의 정밀도는 0.32, Intrusion 공격의 정밀도는 0.33, Malware 공격의 정밀도는 0.34. 정밀도의 값들이 낮은 값으로 나타나는 것을 보아 예측이 정확하지 않다는 것을 알 수 있음.
- **재현율**: DDoS 공격의 재현율은 0.34, 침입(Intrusion) 공격의 재현율은 0.32, 악성코드(Malware) 공격의 재현율은 0.33임. 재현율이 낮다는 것은 모델이 실제로 존재하는 공격을 놓치는 경우가 많다는 것을 알 수 있음.
- **F1 점수**: F1 점수는 정밀도와 재현율의 조화 평균으로, 두 지표의 균형을 나타냄. DDoS 공격의 F1 점수는 0.33, 침입(Intrusion) 공격의 F1 점수는 0.33, 악성코드(Malware) 공격의 F1 점수는 0.34임. F1 점수가 낮고 비슷한 수준이라는 것은 모델이 정밀도와 재현율 모두에서 좋지 않은 성능을 가진 모델이라는 것을 알 수 있음.

#### 2) 랜덤 포레스트
특성 중요도 추출 결과 상위 5개 특성을 기반으로 훈련됨.

- Packet Length, Anomaly Scores, hour, month, day_of_week

|   | 튜닝 전 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.34 | 0.32 |  |
| 재현율 | 0.37 | 0.31 | 0.31 |  |
| F1 점수 | 0.35 | 0.32 | 0.32 | |
| 정확도 |  | | 0.33 | |

|   | 튜닝 후 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.33 | 0.34 |  |
| 재현율 | 0.42 | 0.26 | 0.33 |  |
| F1 점수 | 0.37 | 0.29 | 0.33 |  |
| 정확도 | | | 0.33 | |

- **결론**: 하이퍼파라미터 튜닝을 통해 일부 성능 지표가 개선되었지만, 전체적인 모델 성능은 여전히 낮은 편임.


#### 3) SVM
최적의 파라미터 값을 찾은 후 튜닝 전후를 비교함.

- 'C': 10, 'gamma': 'scale', 'kernel': 'linear'

|   | 튜닝 전 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.33 | 0.34 |  |
| 재현율 | 0.41 | 0.23 | 0.36 |  |
| F1 점수 | 0.37 | 0.27 | 0.35 |  |
| 정확도 | | | 0.33 | |


|   | 튜닝 후 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.33 | 0.33 |  |
| 재현율 | 0.35 | 0.30 | 0.34 |  |
| F1 점수 | 0.34 | 0.31 | 0.33 |  |
| 정확도 | | | 0.33 | |

- **결론**: 튜닝 후 전체적인 성능이 감소. 기본값으로 진행했을 때 더 나은 성능을 보이지만, 그럼에도 여전히 낮은 성능을 보임.

#### 4) 심층 신경망
**튜닝 전**
- 클래스 0에서 상대적으로 높은 재현율을 보임.

|   | 튜닝 전 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.34 | 0.35 | 0.33 |  |
| 재현율 | 0.44 | 0.32 | 0.25 |  |
| F1 점수 | 0.38 | 0.34 | 0.28 |  |
| 정확도 | | | 0.34 | |

**튜닝 후**
- 클래스 0의 재현율은 0.34로 감소, 클래스 1은 0.29, 클래스 2는 0.36으로 전반적으로 낮은 재현율을 보임.

|   | 튜닝 후 |  |  |  |
|---|---------|---|---|---|
| 클래스 | 0 | 1 | 2 |  |
| 정밀도 | 0.33 | 0.34 | 0.33 |  |
| 재현율 | 0.34 | 0.29 | 0.31 |  |
| F1 점수 | 0.32 | 0.36 | 0.34 |  |
| 정확도 | | | 0.33 | |

- **정확성**: 모델 1(튜닝 전)과 모델 2(튜닝 후)의 precision 값은 비슷한 수준임. 모델 1이 클래스 1에서 약간 더 높은 precision(0.35)을 보이고, 나머지 클래스에서는 비슷한 수준.
- **재현율**: 모델 1의 recall은 클래스 0에서 0.44로 가장 높고, 클래스 1은 0.32, 클래스 2는 0.25입니다. 반면, 모델 2는 클래스 0에서 0.34, 클래스 1에서 0.29, 클래스 2에서 0.36으로 전반적으로 낮은 recall을 보임. 모델 1이 클래스 0에 대해 더 잘 예측하고 있음을 나타냄.
- **F1-Score**: 모델 1의 f1-score는 클래스 0에서 0.38로 가장 높고, 나머지 클래스에서는 모델 1이 더 나은 성능(클래스 1: 0.34, 클래스 2: 0.28)을 보임. 모델 2의 f1-score는 전반적으로 낮음.
- **Accuracy**: 두 모델 모두 비슷한 accuracy를 보임. 모델 1의 accuracy는 0.34, 모델 2는 0.33입니다. 두 모델 모두 낮은 accuracy를 보이고 있음.

### 5-2. 성능 평가 결과
#### 1) 정확도
- 세 모델 모두 유사한 수준의 낮은 정확도를 보임. 데이터 불균형, 특성 선택, 모델의 복잡성 등의 원인이 있다고 판단됨.

#### 2) 정밀도, 재현율, F1-Score
- DNN이 클래스 0에서 가장 높은 재현율과 F1-Score를 기록했지만, 전반적으로 모든 모델이 낮은 성능을 보임.
- 랜덤 포레스트와 SVM은 특정 클래스에서는 좋은 성능을 보임. 모델에 따라 특정 클래스에 대한 예측 성능이 달라짐.

### 5-3. 결론
- 현재 데이터셋과 특성 조합으로는 네 모델 모두 유의미한 성능을 발휘하지 못함.
- 적절치 못한 특성 선택, 하이퍼파라미터 부족 등의 문제가 복합적으로 작용했다고 판단됨.
- 향후 데이터 전처리, 특성 엔지니어링, 하이퍼파라미터 튜닝, 앙상블 기법, 모델의 다양화 등을 시도하여 성능을 개선할 수 있음.

---
